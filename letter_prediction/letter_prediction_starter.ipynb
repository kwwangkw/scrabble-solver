{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Letter prediction starter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_4gYLqNKj1Bn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm2d(1)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        self.norm2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.avg1 = nn.AvgPool2d(4, stride=2)\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        self.norm3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.norm4 = nn.BatchNorm2d(32)\n",
        "        self.drop3 = nn.Dropout(0.1)\n",
        "\n",
        "        self.avg2 = nn.AvgPool2d(4, stride=2)\n",
        "        self.norm5 = nn.BatchNorm2d(32)\n",
        "        self.drop4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.avg3 = nn.AvgPool2d(4, stride=2)\n",
        "        self.norm7 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(128, 64)\n",
        "        self.drop6 = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(64, 27)\n",
        "  \n",
        "    def forward(self, x):\n",
        "        relu = nn.ReLU()\n",
        "\n",
        "        x = self.norm1(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm2(x)\n",
        "        x = relu(x)\n",
        "\n",
        "        x = self.avg1(x)\n",
        "        x = self.drop2(x)\n",
        "        x = self.norm3(x)\n",
        "        x = relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.norm4(x)\n",
        "        x = relu(x)\n",
        "\n",
        "        x = self.avg2(x)\n",
        "        x = self.norm5(x)\n",
        "        x = self.drop4(x)\n",
        "        x = relu(x)\n",
        "\n",
        "        x = self.avg3(x)\n",
        "        x = self.norm7(x)\n",
        "        x = relu(x)\n",
        "\n",
        "\n",
        "        x = x.view(-1,x.shape[1] * x.shape[2] * x.shape[3])\n",
        "        x = self.fc1(x)\n",
        "        x = self.drop6(x)\n",
        "        x = relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "I0wjWSlXpP-c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes in PIL image and processes it in preparation for model\n",
        "def process_img(img):\n",
        "  transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Normalize(0, 1)\n",
        "  ])\n",
        "  img.thumbnail((32, 32))\n",
        "  img_arr = np.asarray(img)\n",
        "  if len(img_arr.shape) < 3:\n",
        "    img_arr = np.expand_dims(img_arr, 2)\n",
        "    img_arr = np.repeat(img_arr, 3, 2)\n",
        "  if img_arr.shape[2] > 3:\n",
        "    img_arr = img_arr[:,:,:3]\n",
        "\n",
        "  tpad = (32 - img_arr.shape[0]) // 2\n",
        "  bpad = 32 - tpad - img_arr.shape[0]\n",
        "  lpad = (32 - img_arr.shape[1]) // 2\n",
        "  rpad = 32 - img_arr.shape[1] - lpad\n",
        "\n",
        "  img_arr = np.pad(img_arr, ((tpad, bpad), (lpad, rpad), (0, 0)))\n",
        "  img_arr = img_arr.transpose(2, 0, 1).astype(np.double) / 256\n",
        "  img_tensor = transform(torch.Tensor(img_arr))\n",
        "  return img_tensor"
      ],
      "metadata": {
        "id": "igpzV0mCj4qe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes in PIL image and gives letter prediction. Returns None if prediction is a blank tile.\n",
        "def get_prediction(img, model):\n",
        "  img_arr = process_img(img)\n",
        "  img_arr = img_arr.reshape(1, *img_arr.shape) # Reshape to include batch dimension\n",
        "  model.eval()\n",
        "  pred = torch.softmax(model(img_arr), 1).argmax(1)[0]\n",
        "  if pred == 36:\n",
        "    return None\n",
        "  else:\n",
        "    return chr(65 + pred)"
      ],
      "metadata": {
        "id": "yimTmmaMj78m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = Network()\n",
        "# Load pretrained model weights\n",
        "state_dict = torch.load(\"letter_model_state.sav\", map_location=torch.device('cpu'))\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnnprc0WmESy",
        "outputId": "3c3b4812-71b3-4313-c16d-f777fb2db12d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image from file and get prediction\n",
        "img = Image.open(\"o.png\")\n",
        "get_prediction(img, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yGjdFxmVnI1G",
        "outputId": "62f96644-2ad5-4c30-9ce6-990d61c2f600"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}